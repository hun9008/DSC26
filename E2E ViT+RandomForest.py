import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
import warnings
import matplotlib.pyplot as plt
import platform

# ğŸ”¹ ViT import
from torchvision.models import vit_b_16, ViT_B_16_Weights

# 1. í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif platform.system() == 'Darwin':
    plt.rcParams['font.family'] = 'AppleGothic'
elif platform.system() == 'Linux':
    plt.rcParams['font.family'] = 'NanumGothic'

# 2. ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€
plt.rcParams['axes.unicode_minus'] = False

warnings.filterwarnings('ignore')


def evaluate_score_general(
    y_ng,            # NG=1, Good=0 (Series or 1D array)
    prob_ng,         # NGì¼ í™•ë¥  (predict_proba()[:,1])
    n_select_each=200,
    profit_good=100,
    cost_ng=2000
):
    y_ng = np.asarray(y_ng)
    prob_ng = np.asarray(prob_ng)
    n = len(y_ng)
    assert len(prob_ng) == n

    # Goodì„ 1, NGë¥¼ 0ìœ¼ë¡œ ë³€í™˜
    y_good = 1 - y_ng
    prob_good = 1.0 - prob_ng

    eval_df = pd.DataFrame({
        "y_good": y_good,
        "prob_ng": prob_ng,
        "prob_good": prob_good
    })

    # L/P ë°˜ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    half = n // 2
    eval_df["decision"] = False

    # ê° êµ¬ê°„ì—ì„œ NG í™•ë¥ ì´ ë‚®ì€ ìˆœìœ¼ë¡œ n_select_eachê°œ ì„ íƒ
    top_L = eval_df.iloc[:half].sort_values("prob_ng").iloc[:n_select_each].index
    top_P = eval_df.iloc[half:].sort_values("prob_ng").iloc[:n_select_each].index

    eval_df.loc[top_L, "decision"] = True
    eval_df.loc[top_P, "decision"] = True

    # ROC-AUC (Good=1, prob_good ì‚¬ìš©)
    roc_auc = roc_auc_score(eval_df["y_good"], eval_df["prob_good"])

    # ì´ìµ ê³„ì‚°
    is_decision = eval_df["decision"]
    is_good = eval_df["y_good"] == 1
    is_ng = eval_df["y_good"] == 0

    total_net_profit = (
        profit_good * (is_decision & is_good).sum()
        - cost_ng * (is_decision & is_ng).sum()
    )

    # ì •ê·œí™”: AUCëŠ” 0.5~1 â†’ 0~1ë¡œ
    part_auc = max(roc_auc - 0.5, 0) / 0.5

    # ì´ë¡ ì  ìµœëŒ€ ì´ìµ = ì „ë¶€ Goodì¸ ê²½ìš°
    n_decision = int(is_decision.sum())
    max_profit = profit_good * n_decision if n_decision > 0 else profit_good

    part_profit = max(total_net_profit, 0) / max_profit if max_profit > 0 else 0.0

    # ë‘˜ ë‹¤ [0,1] ì´ë¯€ë¡œ total_score âˆˆ [0,1]
    total_score = np.sqrt(part_auc * part_profit)

    print(f"ROC-AUC Score        : {roc_auc:.6f}")
    print(f"Total Net Profit     : {total_net_profit}")
    print(f"Final Total Score    : {total_score:.6f}")

    return roc_auc, total_net_profit, total_score


# ----------------------------------------------------
# 1. ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤
# ----------------------------------------------------
class DataProcessor:
    """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.OE = None
        self.Scaler = None
        self.cat_list = None
        self.num_list = None
        self.x_min_global = None
        self.x_max_global = None
        self.y_min_global = None
        self.y_max_global = None
        self.basic_feature_dim = None

    def load_data(self, train_path="./data/train.csv", test_path="./data/test.csv"):
        """ë°ì´í„° ë¡œë”©"""
        self.train = pd.read_csv(train_path)
        self.test = pd.read_csv(test_path)

        print(f"Train shape: {self.train.shape}")
        print(f"Test shape: {self.test.shape}")

        self.train_X_basic = self.train.drop(columns=['Class']).iloc[:, :-256*3]
        self.train_Y = self.train['Class'].apply(lambda x: 1 if x == 'NG' else 0)  # NG=1

        # test ë°ì´í„° ì²˜ë¦¬
        self.test_X_basic = self.test.drop(columns=['ID']).iloc[:, :-256*3]

        print(f"Features shape (Train): {self.train_X_basic.shape}")
        print(f"Features shape (Test): {self.test_X_basic.shape}")
        print(f"Target distribution - Good: {(self.train_Y == 0).sum()}, NG: {(self.train_Y == 1).sum()}")

        return self.train, self.test, self.train_X_basic, self.train_Y, self.test_X_basic

    def setup_basic_preprocessing(self, train_X_basic_df):
        """ê¸°ë³¸ í”¼ì²˜ ì „ì²˜ë¦¬ ì„¤ì • (ì „ì²´ train setìœ¼ë¡œ fit)"""
        self.cat_list = train_X_basic_df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
        self.num_list = sorted(list(set(train_X_basic_df.columns) - set(self.cat_list)))

        self.OE = OneHotEncoder(
            min_frequency=0.01,
            handle_unknown='infrequent_if_exist',
            sparse_output=False
        )
        self.OE.fit(train_X_basic_df[self.cat_list])

        self.Scaler = StandardScaler()
        self.Scaler.fit(train_X_basic_df[self.num_list])

    def preprocess_basic(self, dataset):
        """ê¸°ë³¸ í”¼ì²˜ ì „ì²˜ë¦¬"""
        Xc = self.OE.transform(dataset[self.cat_list])
        Xn = self.Scaler.transform(dataset[self.num_list])
        combined = np.concatenate([Xc, Xn], axis=1)

        if self.basic_feature_dim is None:
            self.basic_feature_dim = combined.shape[1]
            print(f"ê¸°ë³¸ í”¼ì²˜ ì°¨ì›: {self.basic_feature_dim}")

        return combined.astype(np.float32)

    def analyze_coordinate_range(self):
        """ì‹¤ì œ x, y ì¢Œí‘œ ë²”ìœ„ ë¶„ì„"""
        x_cols = [f'x{i}' for i in range(256)]
        y_cols = [f'y{i}' for i in range(256)]

        all_data = pd.concat([self.train, self.test], ignore_index=True)
        x_values = all_data[x_cols].values.flatten()
        y_values = all_data[y_cols].values.flatten()

        x_values = x_values[~np.isnan(x_values)]
        y_values = y_values[~np.isnan(y_values)]

        self.x_min_global = x_values.min()
        self.x_max_global = x_values.max()
        self.y_min_global = y_values.min()
        self.y_max_global = y_values.max()

        print(f"ğŸ“Š ì¢Œí‘œ ë²”ìœ„ ë¶„ì„ ê²°ê³¼:")
        print(f"   X ì¢Œí‘œ ë²”ìœ„: {self.x_min_global:.2f} ~ {self.x_max_global:.2f}")
        print(f"   Y ì¢Œí‘œ ë²”ìœ„: {self.y_min_global:.2f} ~ {self.y_max_global:.2f}")

        return self.x_min_global, self.x_max_global, self.y_min_global, self.y_max_global


# ----------------------------------------------------
# 2. ë˜ìŠ¤í„°í™” í´ë˜ìŠ¤
# ----------------------------------------------------
class SpatialRasterizer:
    def __init__(self, x_min, x_max, y_min, y_max, grid_size=64):
        self.x_min = x_min
        self.x_max = x_max
        self.y_min = y_min
        self.y_max = y_max
        self.grid_size = grid_size
        self.x_range = x_max - x_min if x_max > x_min else 1
        self.y_range = y_max - y_min if y_max > y_min else 1

    def rasterize_with_real_coordinates(self, data_row):
        x_cols = [f'x{i}' for i in range(256)]
        y_cols = [f'y{i}' for i in range(256)]
        p_cols = [f'p{i}' for i in range(256)]

        x_coords = data_row[x_cols].values
        y_coords = data_row[y_cols].values
        p_values = data_row[p_cols].values

        grid = np.zeros((self.grid_size, self.grid_size), dtype=np.float32)
        count_grid = np.zeros((self.grid_size, self.grid_size), dtype=np.int8)

        for i in range(256):
            if not (np.isnan(x_coords[i]) or np.isnan(y_coords[i]) or np.isnan(p_values[i])):
                x_norm = (x_coords[i] - self.x_min) / self.x_range
                y_norm = (y_coords[i] - self.y_min) / self.y_range
                x_idx = int(np.clip(x_norm * (self.grid_size - 1), 0, self.grid_size - 1))
                y_idx = int(np.clip(y_norm * (self.grid_size - 1), 0, self.grid_size - 1))
                grid[y_idx, x_idx] += p_values[i]
                count_grid[y_idx, x_idx] += 1

        mask = count_grid > 0
        grid[mask] = grid[mask] / count_grid[mask]

        return grid


# ----------------------------------------------------
# 3. ViT ê¸°ë°˜ ì´ë¯¸ì§€ ì¸ì½”ë”
# ----------------------------------------------------
class ViTEncoder(nn.Module):
    """
    pre-trained ViT-B/16ì„ ì‚¬ìš©í•´ì„œ (1, 64, 64) ì´ë¯¸ì§€ë¥¼ 768ì°¨ì› featureë¡œ ë³€í™˜
    """
    def __init__(self, freeze_vit=True):
        super(ViTEncoder, self).__init__()
        weights = ViT_B_16_Weights.DEFAULT
        self.vit = vit_b_16(weights=weights)
        # ë¶„ë¥˜ head ì œê±° â†’ ìˆœìˆ˜ feature ì¶”ì¶œ
        self.vit.heads = nn.Identity()
        self.output_dim = 768  # vit_b_16ì˜ ì„ë² ë”© ì°¨ì›

        if freeze_vit:
            for p in self.vit.parameters():
                p.requires_grad = False

    def forward(self, x):
        """
        x: (B, 1, 64, 64)
        ViT ì…ë ¥ì— ë§ê²Œ (B, 3, 224, 224)ë¡œ ë¦¬ì‚¬ì´ì¦ˆ & ì±„ë„ ë³µì œ
        """
        # 1ì±„ë„ â†’ 3ì±„ë„
        x = x.repeat(1, 3, 1, 1)                  # (B, 3, 64, 64)
        # 64x64 â†’ 224x224
        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)
        feats = self.vit(x)                       # (B, 768)
        return feats


# ----------------------------------------------------
# 4. E2E ëª¨ë¸ ì •ì˜ (ViT + Basic MLP)
# ----------------------------------------------------
class FullE2EModel(nn.Module):
    def __init__(self, basic_feature_dim,
                 vit_freeze=True,
                 image_vit_output_dim=768,
                 basic_mlp_output_dim=32):
        super(FullE2EModel, self).__init__()

        # ViT ì¸ì½”ë”
        self.image_vit = ViTEncoder(freeze_vit=vit_freeze)

        # ê¸°ë³¸ í”¼ì²˜ MLP
        self.basic_mlp = nn.Sequential(
            nn.Linear(basic_feature_dim, basic_feature_dim * 2),
            nn.ReLU(),
            nn.BatchNorm1d(basic_feature_dim * 2),
            nn.Dropout(0.3),
            nn.Linear(basic_feature_dim * 2, basic_mlp_output_dim),
            nn.ReLU()
        )

        combined_dim = image_vit_output_dim + basic_mlp_output_dim
        self.head = nn.Sequential(
            nn.Linear(combined_dim, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.3),
            nn.Linear(64, 1)
        )

    def forward(self, x_image, x_basic):
        img_feat = self.image_vit(x_image)          # (B, 768)
        basic_feat = self.basic_mlp(x_basic)        # (B, basic_mlp_output_dim)
        combined = torch.cat((img_feat, basic_feat), dim=1)
        output = self.head(combined)                # (B, 1)
        return output

    def extract_features(self, x_image, x_basic):
        """ë¨¸ë¦¬(head) ì•ê¹Œì§€ì˜ 768+basic_mlp_output_dim feature ë°˜í™˜"""
        img_feat = self.image_vit(x_image)
        basic_feat = self.basic_mlp(x_basic)
        combined = torch.cat((img_feat, basic_feat), dim=1)
        return combined  # (B, 768 + basic_mlp_output_dim)


# ----------------------------------------------------
# 5. ë°ì´í„°ì…‹ í´ë˜ìŠ¤
# ----------------------------------------------------
class MultiModalDataset(Dataset):
    def __init__(self, full_df, basic_features_np, rasterizer, labels_np=None):
        self.full_df = full_df.reset_index(drop=True)
        self.basic_features_np = basic_features_np
        self.rasterizer = rasterizer
        self.labels_np = labels_np
        self.is_test = (labels_np is None)

    def __len__(self):
        return len(self.full_df)

    def __getitem__(self, idx):
        data_row = self.full_df.iloc[idx]
        image_grid = self.rasterizer.rasterize_with_real_coordinates(data_row)
        image_tensor = torch.from_numpy(image_grid).unsqueeze(0)  # (1, 64, 64)
        basic_feat_tensor = torch.from_numpy(self.basic_features_np[idx])

        if self.is_test:
            return image_tensor, basic_feat_tensor
        else:
            label_tensor = torch.tensor(self.labels_np[idx], dtype=torch.float32).view(1)
            return image_tensor, basic_feat_tensor, label_tensor


# ----------------------------------------------------
# 6. ìµœì¢… ì œì¶œ íŒŒì´í”„ë¼ì¸
# ----------------------------------------------------
class ProductionPipeline:
    """ViT + RandomForest í•˜ì´ë¸Œë¦¬ë“œ ìµœì¢… ì œì¶œ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, n_epochs=5, batch_size=32):
        self.data_processor = DataProcessor()
        self.rasterizer = None
        self.cnn_model = None  # ì‚¬ì‹¤ìƒ ViT+MLP E2E ëª¨ë¸
        self.rf_model = None   # RandomForest ëª¨ë¸
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        self.n_epochs = n_epochs
        self.batch_size = batch_size

    def train_cnn_extractor(self, train_loader):
        """E2E ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ViT ê¸°ë°˜ í”¼ì²˜ ì¶”ì¶œê¸°ë¡œ ì‚¬ìš©"""
        self.cnn_model = FullE2EModel(
            basic_feature_dim=self.data_processor.basic_feature_dim,
            vit_freeze=True  # í•„ìš”í•˜ë©´ Falseë¡œ ë°”ê¿”ì„œ ë¯¸ì„¸ì¡°ì •(finetune)
        ).to(self.device)

        optimizer = optim.Adam(
            filter(lambda p: p.requires_grad, self.cnn_model.parameters()),
            lr=1e-3,
            weight_decay=1e-5
        )
        criterion = nn.BCEWithLogitsLoss()

        print("\nğŸ§  ViT ê¸°ë°˜ CNN í”¼ì²˜ ì¶”ì¶œê¸° í•™ìŠµ ì‹œì‘...")

        for epoch in range(self.n_epochs):
            self.cnn_model.train()
            train_loss_total = 0.0

            for img, basic, labels in train_loader:
                img, basic, labels = img.to(self.device), basic.to(self.device), labels.to(self.device)
                optimizer.zero_grad()
                outputs = self.cnn_model(img, basic)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                train_loss_total += loss.item()

            avg_train_loss = train_loss_total / len(train_loader)
            print(f"  Epoch [{epoch+1}/{self.n_epochs}], Train Loss: {avg_train_loss:.4f}")

        torch.save(self.cnn_model.state_dict(), 'production_vit_model.pth')
        print("âœ… ViT ê¸°ë°˜ í”¼ì²˜ ì¶”ì¶œê¸° í•™ìŠµ ì™„ë£Œ ë° ì €ì¥.")

    def extract_cnn_features(self, loader, is_test=False):
        """í•™ìŠµëœ ViT+MLP E2E ëª¨ë¸ë¡œ í”¼ì²˜ ì¶”ì¶œ"""
        if self.cnn_model is None:
            self.cnn_model = FullE2EModel(
                basic_feature_dim=self.data_processor.basic_feature_dim,
                vit_freeze=True
            ).to(self.device)
        self.cnn_model.load_state_dict(torch.load('production_vit_model.pth', map_location=self.device))
        self.cnn_model.eval()

        all_features = []
        with torch.no_grad():
            if is_test:
                for img, basic in loader:
                    img, basic = img.to(self.device), basic.to(self.device)
                    features_batch = self.cnn_model.extract_features(img, basic)
                    all_features.append(features_batch.cpu().numpy())
            else:
                for img, basic, labels in loader:
                    img, basic = img.to(self.device), basic.to(self.device)
                    features_batch = self.cnn_model.extract_features(img, basic)
                    all_features.append(features_batch.cpu().numpy())

        return np.concatenate(all_features, axis=0)

    def run_production_pipeline(self):
        """ìµœì¢… ì œì¶œìš© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸš€ ViT í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìµœì¢… ì œì¶œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("=" * 60)

        # 1. ë°ì´í„° ë¡œë”©
        print("\nğŸ“ 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© (train.csv, test.csv)")
        train_df, test_df, train_X_basic_df, train_Y_series, test_X_basic_df = \
            self.data_processor.load_data(train_path="./data/train.csv", test_path="./data/test.csv")

        # 2. ì¢Œí‘œ ë²”ìœ„ ë¶„ì„
        print("\nğŸ“Š 2ë‹¨ê³„: ì¢Œí‘œ ë²”ìœ„ ë¶„ì„ (Train+Test í†µí•©)")
        x_min, x_max, y_min, y_max = self.data_processor.analyze_coordinate_range()

        # 3. ë˜ìŠ¤í„°í™” ì„¤ì •
        print("\nğŸ¯ 3ë‹¨ê³„: ê³µê°„ ë˜ìŠ¤í„°í™” ì„¤ì •")
        self.rasterizer = SpatialRasterizer(x_min, x_max, y_min, y_max, grid_size=64)

        # 4. ê¸°ë³¸ í”¼ì²˜ ì „ì²˜ë¦¬
        print("\nğŸ”„ 4ë‹¨ê³„: ê¸°ë³¸ í”¼ì²˜ ì „ì²˜ë¦¬ (ì „ì²´ train ë°ì´í„°)")
        self.data_processor.setup_basic_preprocessing(train_X_basic_df)

        X_train_basic_np = self.data_processor.preprocess_basic(train_X_basic_df)
        X_test_basic_np = self.data_processor.preprocess_basic(test_X_basic_df)

        print(f"  ì „ì²˜ë¦¬ëœ ê¸°ë³¸ í”¼ì²˜ í˜•íƒœ (Train): {X_train_basic_np.shape}")
        print(f"  ì „ì²˜ë¦¬ëœ ê¸°ë³¸ í”¼ì²˜ í˜•íƒœ (Test): {X_test_basic_np.shape}")

        # 5. ë°ì´í„°ì…‹/ë¡œë” ìƒì„±
        print("\nğŸ“¦ 5ë‹¨ê³„: ViT í•™ìŠµìš© ë°ì´í„°ì…‹/ë¡œë” ìƒì„±")
        train_dataset = MultiModalDataset(train_df, X_train_basic_np, self.rasterizer, train_Y_series.values)
        test_dataset = MultiModalDataset(test_df, X_test_basic_np, self.rasterizer, labels_np=None)

        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)

        # 6. ViT ê¸°ë°˜ í”¼ì²˜ ì¶”ì¶œê¸° í•™ìŠµ
        print("\nğŸ§  6ë‹¨ê³„: ViT ê¸°ë°˜ í”¼ì²˜ ì¶”ì¶œê¸° í•™ìŠµ")
        self.train_cnn_extractor(train_loader)

        # 7. ViT í”¼ì²˜ ì¶”ì¶œ
        print("\nâœ¨ 7ë‹¨ê³„: ViT í”¼ì²˜ ì¶”ì¶œ (Train/Test)")
        train_loader_seq = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False)

        X_train_cnn_feats = self.extract_cnn_features(train_loader_seq, is_test=False)
        X_test_cnn_feats = self.extract_cnn_features(test_loader, is_test=True)

        print(f"  ì¶”ì¶œëœ ViT+MLP í”¼ì²˜ í˜•íƒœ (Train): {X_train_cnn_feats.shape}")
        print(f"  ì¶”ì¶œëœ ViT+MLP í”¼ì²˜ í˜•íƒœ (Test): {X_test_cnn_feats.shape}")

        # 8. í•˜ì´ë¸Œë¦¬ë“œ í”¼ì²˜ ê²°í•©
        print("\nğŸ§¬ 8ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ í”¼ì²˜ ê²°í•© (ê¸°ë³¸ + ViT)")
        X_train_hybrid = np.concatenate([X_train_basic_np, X_train_cnn_feats], axis=1)
        X_test_hybrid = np.concatenate([X_test_basic_np, X_test_cnn_feats], axis=1)

        print(f"  í•˜ì´ë¸Œë¦¬ë“œ í”¼ì²˜ í˜•íƒœ (Train): {X_train_hybrid.shape}")
        print(f"  í•˜ì´ë¸Œë¦¬ë“œ í”¼ì²˜ í˜•íƒœ (Test): {X_test_hybrid.shape}")

        # 9. RandomForest í•™ìŠµ
        print("\nğŸ¤– 9ë‹¨ê³„: RandomForest ëª¨ë¸ í•™ìŠµ (í•˜ì´ë¸Œë¦¬ë“œ í”¼ì²˜)")
        self.rf_model = RandomForestClassifier(
            random_state=42,
            n_estimators=200,
            n_jobs=-1
        )
        self.rf_model.fit(X_train_hybrid, train_Y_series)
        print("âœ… RandomForest ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.")

        # 10. Train ì„±ëŠ¥ í‰ê°€
        print("\nğŸ” 10ë‹¨ê³„: Train ì„±ëŠ¥ í‰ê°€ (ROC-AUC, Total Net Profit, Final Score)")
        train_prob_ng = self.rf_model.predict_proba(X_train_hybrid)[:, 1]
        roc_auc, total_net_profit, total_score = evaluate_score_general(
            y_ng=train_Y_series.values,
            prob_ng=train_prob_ng,
            n_select_each=200,
            profit_good=100,
            cost_ng=2000
        )

        # 11. Test ì˜ˆì¸¡
        print("\nğŸ”® 11ë‹¨ê³„: Test ë°ì´í„° ë¶ˆëŸ‰ë¥  ì˜ˆì¸¡")
        test_prob = self.rf_model.predict_proba(X_test_hybrid)[:, 1]
        print(f"  ì˜ˆì¸¡ ì™„ë£Œ: {len(test_prob)}ê°œ ìƒ˜í”Œ")
        print(f"  ë¶ˆëŸ‰ë¥  ë²”ìœ„: {test_prob.min():.4f} ~ {test_prob.max():.4f}")

        # 12. ì œì¶œ íŒŒì¼ ìƒì„±
        print("\nğŸ“ 12ë‹¨ê³„: ì œì¶œ íŒŒì¼ ìƒì„±")
        submission = pd.read_csv("./data/sample_submission.csv")
        submission['probability'] = np.concatenate([test_prob, test_prob])

        decision_id_L_list = submission.iloc[:466].sort_values('probability').iloc[:200]['ID']
        decision_id_P_list = submission.iloc[466:].sort_values('probability').iloc[:200]['ID']

        submission.loc[submission['ID'].isin(decision_id_L_list), 'decision'] = True
        submission.loc[submission['ID'].isin(decision_id_P_list), 'decision'] = True

        submission.to_csv("./data/hybrid_vit_submission.csv", index=False)

        print("âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: hybrid_vit_submission.csv")
        print(f"   - L íƒ€ì…ì—ì„œ ì„ íƒëœ ê°œìˆ˜: {len(decision_id_L_list)}")
        print(f"   - P íƒ€ì…ì—ì„œ ì„ íƒëœ ê°œìˆ˜: {len(decision_id_P_list)}")
        print(f"   - ì´ ì„ íƒëœ ê°œìˆ˜: {len(decision_id_L_list) + len(decision_id_P_list)}")

        print("\n" + "=" * 60)
        print("ğŸ‰ ViT í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìµœì¢… ì œì¶œ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        print("=" * 60)
        print(f"  ğŸ”¹ ì‚¬ìš©ëœ í”¼ì²˜: ê¸°ë³¸ í”¼ì²˜ ({self.data_processor.basic_feature_dim}ì°¨ì›)"
              f" + ViT+MLP í”¼ì²˜ ({X_train_cnn_feats.shape[1]}ì°¨ì›)")
        print(f"  ğŸ”¹ ìµœì¢… í”¼ì²˜ ì°¨ì›: {X_train_hybrid.shape[1]}ì°¨ì›")
        print(f"  ğŸ”¹ í•™ìŠµ ë°ì´í„°: {len(train_Y_series)}ê°œ"
              f" (NG: {train_Y_series.sum()}ê°œ, Good: {len(train_Y_series)-train_Y_series.sum()}ê°œ)")
        print(f"  ğŸ”¹ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_prob)}ê°œ")
        print(f"  ğŸ”¹ ì œì¶œ íŒŒì¼: hybrid_vit_submission.csv")
        print("=" * 60)

        return submission


def main():
    pipeline = ProductionPipeline(n_epochs=5, batch_size=32)
    submission_result = pipeline.run_production_pipeline()

    print("\nğŸ“‹ ì œì¶œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°:")
    print(submission_result.head(10))
    print("...")
    print(submission_result.tail(10))

    selected_count = submission_result['decision'].sum()
    print(f"\nâœ… ìµœì¢… ì„ íƒëœ ì œí’ˆ ê°œìˆ˜: {selected_count}ê°œ")


if __name__ == "__main__":
    main()